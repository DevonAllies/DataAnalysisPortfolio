[
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Data Science Projects",
    "section": "",
    "text": "Covid 19 Dataset\n\n\n\n\n\n\nDevon Allies, BSc. Honours: Bioinformatics & Computational Biology\n\n\n\n\n\n\n\n\n\n\n\n\n\nTBTrends:\n\n\n\n\n\n\nDevon Allies\n\n\n\n\n\n\n\n\n\n\n\n\n\nPathogen Identification from Clinical Metagenomics Data\n\n\nThis analysis focuses on identifying a potential pathogen from clinical metagenomics data. The workflow includes quality control of sequencing reads, host depletion, de novo…\n\n\n\nDevon Allies\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/tbTrends/TBTrendsEDA.html",
    "href": "projects/tbTrends/TBTrendsEDA.html",
    "title": "TBTrends:",
    "section": "",
    "text": "Tuberculosis (TB) remains a significant global health challenge, affecting millions of people worldwide, particularly in Africa, Asia, and Latin America. The World Health Organization (WHO) adopted a blueprint in 2014, the End TB Strategy, which aims to reduce incidence by 80% by the year 2030, using the year 2015 as a baseline.\nThis project conducts an exploratory data analysis (EDA) of the Tuberculosis_Trends.csv (Kyada, 2024) dataset available on Kaggle, which captures comprehensive country-level public health data from 2000 - 2024. The primary objective is to uncover patterns and relationships between TB indicators (cases, mortality, treatment success) and various socio-economic and health infrastructure metrics to identify key drivers of disease prevalence. Specifically, this analysis aims to answer:\n\nHow have TB cases and deaths trended in South Africa compared to other regions?\nWhat socio-economic or health infrastructure factors show the strongest correlation with reduced TB burden?\nDoes the current trajectory indicate South Africa will meet the 2030 reduction targets?"
  },
  {
    "objectID": "projects/tbTrends/TBTrendsEDA.html#introduction",
    "href": "projects/tbTrends/TBTrendsEDA.html#introduction",
    "title": "TBTrends:",
    "section": "",
    "text": "Tuberculosis (TB) remains a significant global health challenge, affecting millions of people worldwide, particularly in Africa, Asia, and Latin America. The World Health Organization (WHO) adopted a blueprint in 2014, the End TB Strategy, which aims to reduce incidence by 80% by the year 2030, using the year 2015 as a baseline.\nThis project conducts an exploratory data analysis (EDA) of the Tuberculosis_Trends.csv (Kyada, 2024) dataset available on Kaggle, which captures comprehensive country-level public health data from 2000 - 2024. The primary objective is to uncover patterns and relationships between TB indicators (cases, mortality, treatment success) and various socio-economic and health infrastructure metrics to identify key drivers of disease prevalence. Specifically, this analysis aims to answer:\n\nHow have TB cases and deaths trended in South Africa compared to other regions?\nWhat socio-economic or health infrastructure factors show the strongest correlation with reduced TB burden?\nDoes the current trajectory indicate South Africa will meet the 2030 reduction targets?"
  },
  {
    "objectID": "projects/tbTrends/TBTrendsEDA.html#import-modules",
    "href": "projects/tbTrends/TBTrendsEDA.html#import-modules",
    "title": "TBTrends:",
    "section": "Import modules:",
    "text": "Import modules:\nAnalysis was conducted primarily using Python, leveraging key libraries from the scientific Python ecosystem: pandas (team, 2020) for data manipulation, Numpy (Harris et al., 2020) for numerical operations, Seaborn (Waskom, 2021), Matplotlib (Hunter, 2007) for visualization, and SciPy (Virtanen et al., 2020) for scientific computing.\nThe following script outlines the necessary modules imported to facilitate the project’s data processing and exploratory visualization stages:\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport math\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\nsns.set()\n\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom statsmodels.tsa.holtwinters import ExponentialSmoothing"
  },
  {
    "objectID": "projects/tbTrends/TBTrendsEDA.html#load-dataset",
    "href": "projects/tbTrends/TBTrendsEDA.html#load-dataset",
    "title": "TBTrends:",
    "section": "Load dataset:",
    "text": "Load dataset:\nThis step involves loading the raw Tuberculosis_Trends.csv file into a structured data format using the pandas module. The pd.read_csv() function is used to read the data from the local file path into a DataFrame named data for subsequent analysis. This action transforms the raw comma-separated values into a manipulable table.\n\ndata = pd.read_csv('Tuberculosis_Trends.csv')"
  },
  {
    "objectID": "projects/tbTrends/TBTrendsEDA.html#data-scope-and-key-variables",
    "href": "projects/tbTrends/TBTrendsEDA.html#data-scope-and-key-variables",
    "title": "TBTrends:",
    "section": "Data Scope and Key Variables:",
    "text": "Data Scope and Key Variables:\n\n\n\nTable 1: Dataset feature descriptions, data types, and non-null counts.\n\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 3000 entries, 0 to 2999\nData columns (total 22 columns):\n #   Column                         Non-Null Count  Dtype  \n---  ------                         --------------  -----  \n 0   Country                        3000 non-null   object \n 1   Region                         3000 non-null   object \n 2   Income_Level                   3000 non-null   object \n 3   Year                           3000 non-null   int64  \n 4   TB_Cases                       3000 non-null   int64  \n 5   TB_Deaths                      3000 non-null   int64  \n 6   TB_Incidence_Rate              3000 non-null   float64\n 7   TB_Mortality_Rate              3000 non-null   float64\n 8   TB_Treatment_Success_Rate      3000 non-null   float64\n 9   Drug_Resistant_TB_Cases        3000 non-null   int64  \n 10  HIV_CoInfected_TB_Cases        3000 non-null   int64  \n 11  Population                     3000 non-null   int64  \n 12  GDP_Per_Capita                 3000 non-null   int64  \n 13  Health_Expenditure_Per_Capita  3000 non-null   int64  \n 14  Urban_Population_Percentage    3000 non-null   float64\n 15  Malnutrition_Prevalence        3000 non-null   float64\n 16  Smoking_Prevalence             3000 non-null   float64\n 17  TB_Doctors_Per_100K            3000 non-null   float64\n 18  TB_Hospitals_Per_Million       3000 non-null   float64\n 19  Access_To_Health_Services      3000 non-null   float64\n 20  BCG_Vaccination_Coverage       3000 non-null   float64\n 21  HIV_Testing_Coverage           3000 non-null   float64\ndtypes: float64(11), int64(8), object(3)\nmemory usage: 515.8+ KB\n\n\n\n\nAn initial overview of the column information confirms a robust dataset, providing ample scope for exploring complex relationships. For this project, key variables of interest include TB_Incidence_Rate, TB_Mortality_Rate, GDP_Per_Capita, Health_Expenditure_Per_Capita, and BCG_Vaccination_Coverage, as these directly relate to potential drivers of disease prevaence outlined in the problem statement.\n\nData quality Assessment:\n\n\n\nTable 2: Confirmation of zero missing values across all 22 features, ensuring high data reliability.\n\n\n\nCountry                          0\nRegion                           0\nIncome_Level                     0\nYear                             0\nTB_Cases                         0\nTB_Deaths                        0\nTB_Incidence_Rate                0\nTB_Mortality_Rate                0\nTB_Treatment_Success_Rate        0\nDrug_Resistant_TB_Cases          0\nHIV_CoInfected_TB_Cases          0\nPopulation                       0\nGDP_Per_Capita                   0\nHealth_Expenditure_Per_Capita    0\nUrban_Population_Percentage      0\nMalnutrition_Prevalence          0\nSmoking_Prevalence               0\nTB_Doctors_Per_100K              0\nTB_Hospitals_Per_Million         0\nAccess_To_Health_Services        0\nBCG_Vaccination_Coverage         0\nHIV_Testing_Coverage             0\ndtype: int64\n\n\n\n\nThis high quality is a significant advantage, as real-world health data is often messy. The completeness of the data for this analysis minimizes potential biases from imputation methods and strengthens the reliability of all subsequent findings and the predictive model’s accuracy.\n\n\n\n\n\n\n\n\nFigure 1: TB cases over time (2000 - 2024), illustrating persistent disparities between Asia / Africa (high) and North America / Europe (low).\n\n\n\n\n\nThe persistent disparity between high-burden regions (Asia, Africa) and low-burden regions (North America, Europe) underscores the critical need for targeted, context-specific interventions. This initial observation justifies a deeper dive into country-level socio-economic factors (e.g., GDP, health expenditure) to understand the drivers behind these regional differences, rather than just observing them.\n\n\n\n\n\n\n\n\nFigure 2: Annual TB cases in South Africa (2000 - 2024), showing fluctuation with a slight downward trend.\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 3: Annual TB deaths in South Africa (2000 - 2024).\n\n\n\n\n\nFigure 2 and Figure 3 provide a granular view of South Africa. While TB cases have fluctuated, there is a general trend of decreasing TB deaths since the early 2000s, indicating potential improvements in treatment efficacy or access to care.\nThe official death counts can be complex due to reporting issues (e.g., HIV and TB are often under-reported on death certificates).\n\n\n\n\n\n\n\n\nFigure 4: Drug Resistant TB Cases observed in South Africa.\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 5: HIV Co-Infected TB Cases observed in South Africa.\n\n\n\n\n\nFigure 4 and Figure 5 highlights the persistent challenges of drug-resistant TB and HIV co-infection within South Africa. The trends for HIV co-infected cases show considerable variability, with peaks around 2005 and 2015, suggesting a need for targeted interventions."
  },
  {
    "objectID": "projects/tbTrends/TBTrendsEDA.html#determining-correlation",
    "href": "projects/tbTrends/TBTrendsEDA.html#determining-correlation",
    "title": "TBTrends:",
    "section": "Determining Correlation:",
    "text": "Determining Correlation:\n\n\n\n\n\n\n\n\nFigure 6: Pearson correlation matrix for South Africa’s health metrics; Access to Health Services shows the strongest negative correlation with TB Deaths.\n\n\n\n\n\nFigure 6 presents a correlation heatmap generated from the Pearson correlation coefficients calculated for South Africa’s data.\nThe observed weak correlations for most variables are typical of complex, multifactorial public health issues, highlighting that no single factor operates in isolation.\nThe strongest correlation observed in South Africa is the negative relationship between Access_To_Health_Services and TB_Deaths. This insight is a key takeaway: increasing access to care is potentially the single most impactful structural intervention for reducing TB mortality, which can directly inform policy and resource allocation."
  },
  {
    "objectID": "projects/tbTrends/TBTrendsEDA.html#predictive-modeling",
    "href": "projects/tbTrends/TBTrendsEDA.html#predictive-modeling",
    "title": "TBTrends:",
    "section": "Predictive Modeling:",
    "text": "Predictive Modeling:\n\n\n\nTable 3\n\n\n\n\n\nFeatures Used in Model (X)\n\n\n\n\nYear\n\n\nTB_Deaths\n\n\nTB_Incidence_Rate\n\n\nTB_Mortality_Rate\n\n\nTB_Treatment_Success_Rate\n\n\nDrug_Resistant_TB_Cases\n\n\nHIV_CoInfected_TB_Cases\n\n\nPopulation\n\n\nGDP_Per_Capita\n\n\nHealth_Expenditure_Per_Capita\n\n\nUrban_Population_Percentage\n\n\nMalnutrition_Prevalence\n\n\nSmoking_Prevalence\n\n\nTB_Doctors_Per_100K\n\n\nTB_Hospitals_Per_Million\n\n\nAccess_To_Health_Services\n\n\nBCG_Vaccination_Coverage\n\n\nHIV_Testing_Coverage\n\n\n\n\n\n\nTo move beyond exploratory analysis and assess the potential for forecasting disease burden, a Random Forest Regressor model was trained to predict TB_Cases in South Africa. The dataset was split into training and testing sets.\n\n\n| Hyperparameter    |   Optimal Value |\n|:------------------|----------------:|\n| max_depth         |              10 |\n| min_samples_split |              10 |\n| n_estimators      |              50 |\n\n\n\n\nTable 4: Hypertuning Results using GridSearchCV\n\n\n\nGridSearchCV(cv=5, estimator=RandomForestRegressor(random_state=12345),\n             param_grid={'max_depth': [None, 10, 20, 30],\n                         'min_samples_split': [2, 5, 10],\n                         'n_estimators': [50, 100, 150, 200]},\n             scoring='neg_mean_squared_error')In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.GridSearchCV?Documentation for GridSearchCViFitted\n        \n            \n                Parameters\n                \n\n\n\n\nestimator \nRandomForestR...m_state=12345)\n\n\n\nparam_grid \n{'max_depth': [None, 10, ...], 'min_samples_split': [2, 5, ...], 'n_estimators': [50, 100, ...]}\n\n\n\nscoring \n'neg_mean_squared_error'\n\n\n\nn_jobs \nNone\n\n\n\nrefit \nTrue\n\n\n\ncv \n5\n\n\n\nverbose \n0\n\n\n\npre_dispatch \n'2*n_jobs'\n\n\n\nerror_score \nnan\n\n\n\nreturn_train_score \nFalse\n\n\n\n\n            \n        \n    best_estimator_: RandomForestRegressorRandomForestRegressor(max_depth=10, min_samples_split=10, n_estimators=50,\n                      random_state=12345)RandomForestRegressor?Documentation for RandomForestRegressor\n        \n            \n                Parameters\n                \n\n\n\n\nn_estimators \n50\n\n\n\ncriterion \n'squared_error'\n\n\n\nmax_depth \n10\n\n\n\nmin_samples_split \n10\n\n\n\nmin_samples_leaf \n1\n\n\n\nmin_weight_fraction_leaf \n0.0\n\n\n\nmax_features \n1.0\n\n\n\nmax_leaf_nodes \nNone\n\n\n\nmin_impurity_decrease \n0.0\n\n\n\nbootstrap \nTrue\n\n\n\noob_score \nFalse\n\n\n\nn_jobs \nNone\n\n\n\nrandom_state \n12345\n\n\n\nverbose \n0\n\n\n\nwarm_start \nFalse\n\n\n\nccp_alpha \n0.0\n\n\n\nmax_samples \nNone\n\n\n\nmonotonic_cst \nNone\n\n\n\n\n            \n        \n    \n\n\n\n\n\nGridSearchCV was employed to systematically identify the optimal model configuration, balancing predictive accuracy with the risk of overfitting. The finalized hyperparameters (max depth 10, min samples split 10, n_estimators 50) ensure the model provides robust, generalized predictions.\n\n\n\n\nRandomForestRegressor(max_depth=10, min_samples_split=10, n_estimators=50,\n                      random_state=12345)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.RandomForestRegressor?Documentation for RandomForestRegressoriFitted\n        \n            \n                Parameters\n                \n\n\n\n\nn_estimators \n50\n\n\n\ncriterion \n'squared_error'\n\n\n\nmax_depth \n10\n\n\n\nmin_samples_split \n10\n\n\n\nmin_samples_leaf \n1\n\n\n\nmin_weight_fraction_leaf \n0.0\n\n\n\nmax_features \n1.0\n\n\n\nmax_leaf_nodes \nNone\n\n\n\nmin_impurity_decrease \n0.0\n\n\n\nbootstrap \nTrue\n\n\n\noob_score \nFalse\n\n\n\nn_jobs \nNone\n\n\n\nrandom_state \n12345\n\n\n\nverbose \n0\n\n\n\nwarm_start \nFalse\n\n\n\nccp_alpha \n0.0\n\n\n\nmax_samples \nNone\n\n\n\nmonotonic_cst \nNone\n\n\n\n\n            \n        \n    \n\n\nFigure 7: Feature importance for predicting TB cases; Population, Treatment Success Rate, and GDP per Capita are identified as key drivers.\n\n\n\n\n\n\n\n\n\n\nFigure 8: Feature importance for predicting TB cases; Population, Treatment Success Rate, and GDP per Capita are identified as key drivers.\n\n\n\n\n\n?@fig-feature-selection illustrates the derived feature importance from the Random Forest model. It highlights that while demographic factors like Population are a major driver (naturally, more people mean more cases), actionable health metrics such as TB_Treatment_Success_Rate, GDP_Per_Capita, and TB_Deaths also play roles. These findings may guide resource allocation towards improving treatment outcomes and economic conditions as key strategies for reducing disease prevalence."
  },
  {
    "objectID": "projects/tbTrends/TBTrendsEDA.html#who-end-tb-initiative",
    "href": "projects/tbTrends/TBTrendsEDA.html#who-end-tb-initiative",
    "title": "TBTrends:",
    "section": "WHO End TB Initiative:",
    "text": "WHO End TB Initiative:\nThe WHO End TB Strategy is a global health framework and provides a blueprint for countries to reduce TB incidence and deaths, with a vision of world free of TB.\nThe goal is to end the global TB epidemic by achieving specific milestones, including a 90% reduction in TB deaths and a 80% reduction in TB incidence by 2030, compared to 2015 levels.\n\n\nPredicted incidence for 2030: 212.40\n\n\n2015 Baseline: 252.86\n\n\nAchieved Reduction Percentage: 16.00%\n\n\nTarget Achieved Status (1 = Achieved, 0 = Not Achieved): 0\n\n\n\n\n\n\n\n\n\n\nFigure 9: Time Series Forecase determining whether South Africa would reach the 80% reduction."
  },
  {
    "objectID": "projects/tbTrends/TBTrendsEDA.html#conclusion-and-actionable-recommendations",
    "href": "projects/tbTrends/TBTrendsEDA.html#conclusion-and-actionable-recommendations",
    "title": "TBTrends:",
    "section": "Conclusion and Actionable Recommendations:",
    "text": "Conclusion and Actionable Recommendations:\nThis exploratory data analysis and predictive modeling project successfully identified key drivers of tuberculosis prevalence in South Africa and forecasted potential future trends. The analysis highlights that South Africa, under its current trajectory, is not projected to meet the ambitious 80% TB incidence reduction target by 2030.\nKey Takeaways and Insights:\n\nThe strongest negative correlation was found between Access_To_Health_Services and TB_Deaths.\nGDP_Per_Capita and TB_Treatment_Success_Rate were significant features in predicting TB cases, along with general population density.\nThe high variability of HIV co-infected cases highlights a need for better integrated screening and treatment programs.\n\nNext Steps:\nFuture work will involve validating the insights found here by analyzing the official WHO Global TB Report dataset, as the current analysis utilizes a similar but separate dataset obtained via Kaggle. Additionally, future analysis could incorporate more granular geographic data to identify specific TB hotspots, perform cost-effectiveness analysis for the recommended interventions, or explore more advanced time-series models to refine long-term forecasting.\nLimitations:\n\nThe analysis utilized a dataset obtained via Kaggle, which is similar to but separate from the official WHO Global TB Report dataset. Future work would involve validating these insights against the official WHO data.\nThe correlation analysis and predictive modeling were specifically conducted using data only for South Africa, limiting the immediate generalizability of these specific findings to other countries or regions.\nOfficial death counts can be complex due to reporting issues (e.g., HIV and TB are often under-reported on death certificates), which may introduce some bias into the historical data.\nWhile a Random Forest Regressor was used, future analysis could explore more advanced time-series models to refine long-term forecasting accuracy.\n\n\nLicense and Data Usage Terms:\nThe underlying data used in this analysis, Tuberculosis Trends - Global & Regional Insights by Khushi Kyada is provided under the Creative Commons Attribution 4.0 International License (CC BY 4.0).\nAll original source code and analytical work presented in this project is released under the MIT License. A copy of this license is available in the root directory of the project repository (License.txt file). This license grants permission for commercial and non-commercial use, modification, and distribution of the project’s software, provided appropriate credit is given."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Devon Allies - Portfolio of Data Science Projects",
    "section": "",
    "text": "Page under construction"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "With over 10 years of experience in immunology, bioinformatics, and computational biology, I specialise in tuberculosis research, clinical study coordination, and data-driven bioinformatics solutions.\nAs a Project Coordinator at the Division of Molecular Biology and Human Genetics, I manage clinical research projects, streamline operations, and enhance data integrity while ensuring seamless stakeholder collaboration.\nKey Highlights: - Contributed to peer-reviewed research published in PubMed, BMC Infectious Diseases, with 62+ citations in the past five years. - Developed an automated dashboard to improve data logging and retrieval for clinical studies. - Expertise in flow cytometry, PBMC isolation, and immunological assay development in ISO-accredited labs. - Skilled in Python, R, Power BI, SQL, Nextflow, and clinical data management.\nI’m passionate about integrating bioinformatics and computational biology to drive scientific innovation and improve healthcare outcomes. Let’s connect!"
  },
  {
    "objectID": "projects/covid/covid19_eda.html",
    "href": "projects/covid/covid19_eda.html",
    "title": "Covid 19 Dataset",
    "section": "",
    "text": "Coronavirus Disease 2019 (Covid-19) is a highly contagious infectious disease caused by the SARS-CoV-2 virus, which emerged as a global pandemic in early 2020. It primarily spreads through respiratory particles and has impacted global health, economics and societies worldwide.\n\n\nThis Quarto document serves as a exercise in Exploratory Data Analysis (EDA), focusing on a critical public health data-set related to the Covid-19 pandemic. The data, sourced from a collaborative research effort, provides clinical insights into patient outcomes based on complete blood count (CBC) metrics (Rahman et al., 2020) .\n\n\n\nThe data-set was compiled by a team of researches and medical professionals from Qatar University and Dhaka Medical College Hospital, Bangladesh. Data collection occurred between April 12 and August 31, 2020, at the Dhaka Medical College Hospital, following approval from the local Hospital Ethical Committee. This specific time frame places the data collection during a significant early phase of the pandemic (Rahman et al., 2020)."
  },
  {
    "objectID": "projects/covid/covid19_eda.html#introduction",
    "href": "projects/covid/covid19_eda.html#introduction",
    "title": "Covid 19 Dataset",
    "section": "",
    "text": "Coronavirus Disease 2019 (Covid-19) is a highly contagious infectious disease caused by the SARS-CoV-2 virus, which emerged as a global pandemic in early 2020. It primarily spreads through respiratory particles and has impacted global health, economics and societies worldwide.\n\n\nThis Quarto document serves as a exercise in Exploratory Data Analysis (EDA), focusing on a critical public health data-set related to the Covid-19 pandemic. The data, sourced from a collaborative research effort, provides clinical insights into patient outcomes based on complete blood count (CBC) metrics (Rahman et al., 2020) .\n\n\n\nThe data-set was compiled by a team of researches and medical professionals from Qatar University and Dhaka Medical College Hospital, Bangladesh. Data collection occurred between April 12 and August 31, 2020, at the Dhaka Medical College Hospital, following approval from the local Hospital Ethical Committee. This specific time frame places the data collection during a significant early phase of the pandemic (Rahman et al., 2020)."
  },
  {
    "objectID": "projects/covid/covid19_eda.html#import-modules-packages",
    "href": "projects/covid/covid19_eda.html#import-modules-packages",
    "title": "Covid 19 Dataset",
    "section": "Import modules & packages:",
    "text": "Import modules & packages:\nAnalysis was conducted primarily using Python, leveraging key libraries from the scientific Python ecosystem: pandas (team, 2020), Numpy (Harris et al., 2020), Seaborn (Waskom, 2021), Matplotlib (Hunter, 2007), and SciPy (Virtanen et al., 2020).\nFor alternative R analysis, the comprehensive tidyverse package was loaded (Wickham et al., 2019).\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nsns.set()\nimport matplotlib.pyplot as plt\nimport scipy.stats as stats\nfrom scipy.stats import chi2_contingency, ttest_ind\n\n\nlibrary(tidyverse)"
  },
  {
    "objectID": "projects/covid/covid19_eda.html#load-data-set",
    "href": "projects/covid/covid19_eda.html#load-data-set",
    "title": "Covid 19 Dataset",
    "section": "Load data set:",
    "text": "Load data set:\nThis step involves loading the raw COVID-19_CBC_Data.csv file into a data structure using the pandas module. The pd.read_csv() function is used to read the data from the local file path into a DataFrame named data for subsequent analysis.\n\ndata = pd.read_csv('COVID-19_CBC_Data.csv')"
  },
  {
    "objectID": "projects/covid/covid19_eda.html#data-scope-and-key-variables",
    "href": "projects/covid/covid19_eda.html#data-scope-and-key-variables",
    "title": "Covid 19 Dataset",
    "section": "Data Scope and Key Variables:",
    "text": "Data Scope and Key Variables:\nThe data-set captures clinical parameters, demographic data, and patient outcomes for a cohort of 103 patients.\nKey information includes standard CBC metrics, as well as critical outcomes variables: hospital admission status and final results, Recovered or Not Recovered. The data-set is relatively balanced regarding outcomes, with 61 patients surviving and 42 resulting in death.\nThe data.head() function is a standard initial step in EDA. It provides a quick, concise view of the top rows of the DataFrame, allowing us to inspect the data-set’s structure, identify data types, and confirm the initial loading was successful.\n\n\n\nTable 1: Preview Data\n\n\n\n| Gender   |   White blood cell count |   Platelet Count |   Lymphocyte Count |\n|:---------|-------------------------:|-----------------:|-------------------:|\n| Male     |                    21    |           462    |               0.44 |\n| Female   |                     8.79 |           180.66 |               4.39 |\n| Male     |                     9.9  |           336    |               3.47 |\n| Female   |                     9.95 |           240.1  |               0.8  |\n| Male     |                    14.15 |           236.58 |               7.93 |\n| Male     |                    13.3  |           249    |               4.12 |\n| Male     |                     6.7  |           323    |               1.92 |\n| Male     |                    13.33 |           250.01 |               6.53 |\n| Male     |                     5    |           184    |               0.34 |\n| Female   |                    10.32 |           239.25 |               2    |\n\n\n\n\nThis initial inspection confirms that the data has been loaded correctly and provides the foundational understanding required to proceed with more in-depth statistical analysis and visualization."
  },
  {
    "objectID": "projects/covid/covid19_eda.html#data-quality-assessment",
    "href": "projects/covid/covid19_eda.html#data-quality-assessment",
    "title": "Covid 19 Dataset",
    "section": "Data Quality Assessment:",
    "text": "Data Quality Assessment:\n\n\n\nTable 2: Summary of Missing Values per Column\n\n\n\n| Column Name                       |   Missing Count |\n|:----------------------------------|----------------:|\n| Admission_DATE                    |               0 |\n| Discharge_DATE or date of Death   |               0 |\n| Outcome                           |               0 |\n| Patient Age                       |               0 |\n| Gender                            |               0 |\n| Sample Collection Date            |               0 |\n| What kind of Treatment provided   |               0 |\n| Ventilated (Y/N)                  |               0 |\n| Red blood cell distribution width |               0 |\n| Monocytes(%)                      |               0 |\n| White blood cell count            |               0 |\n| Platelet Count                    |               0 |\n| Lymphocyte Count                  |               0 |\n| Neutrophils Count                 |               0 |\n\n\n\n\nThe data-set demonstrates exceptional quality with zero missing values across all 18 features, including demographics, clinical metrics, and outcomes. This completeness eliminates pre-processing needs and enhances analysis reliability. Table 2 confirms full data availability for 103-patient cohort."
  },
  {
    "objectID": "projects/covid/covid19_eda.html#demographic-distributions",
    "href": "projects/covid/covid19_eda.html#demographic-distributions",
    "title": "Covid 19 Dataset",
    "section": "Demographic Distributions:",
    "text": "Demographic Distributions:\n\nPatient Age Distribution:\n\n\n\n\n\n\n\n\nFigure 1: Histogram showing the distribution of patient ages within the dataset.\n\n\n\n\n\nFigure 1 reveals a multimodal age distribution with peaks around 30-40, 50-60, and 60-70 years, spanning 17, 77 years overall. This middle-aged concentration reflects hospital admission patterns during early pandemic waves. Central tendency centers around 46 years with moderate spread (SD \\(\\pm\\) 16)\n\n\nGender Composition:\n\n\n\n\n\n\n\n\nFigure 2: Gender Distribution\n\n\n\n\n\nNearly balanced gender representation, 55 males, 48 females) minimizes sampling bias, as shown in Figure 2. This equilibrium supports gender-stratified analyses without confounding by disproportionate representation.\n\n\nSurvival Pattern Analysis:\n\nAge-Survival Relationship:\n\n\n\n\n\n\n\n\nFigure 3: Age Survival Relationship\n\n\n\n\n\nViolin plots, Figure 3, demonstrates clear age-outcome divergences: recovered patients peak at 30-50 years while non-recovered concentrate above 60 years. Survival rates decline sharply: 87%, &lt; 40 years, 57%, 40-60 years, and 24%, &gt; 60 years.\n\n\n\nTable 3: Survival percentages per Age Group\n\n\n\n| Age Group   |   Recovered % |   Not Recovered % |   n |\n|:------------|--------------:|------------------:|----:|\n| &lt;40         |          87.2 |              12.8 |  39 |\n| 40-60       |          57.1 |              42.9 |  35 |\n| &gt;60         |          24.1 |              75.9 |  29 |\n\n\n\n\n\n\n\nClinical Outcomes by Gender:\n\nGender-Survival Association:\n\n\n\n\n\n\n\n\nFigure 4: Survival by Gender\n\n\n\n\n\nFigure 4 shows proportional recovery rates (\\(\\pm\\) 59% overall) identical across genders despite higher raw non-recovery counts among males.\n\n\n\nClinical Trajectory Metics:\n\nHospital Length Stay:\nLength of Stay (LOS), Figure 5, reveal shorter median stays for recovered patients versus prolonged stays for non-recovered cases, reflecting disease severity.\n\n\n\n\n\n\n\n\nFigure 5: Length of Stay\n\n\n\n\n\n\n\nVentilation and Treatment Analysis:\n\n\n\nTable 4: Ventilation and treatment analysis\n\n\n\n| Ventilated (Y/N)   |   Not Recovered |   Recovered |\n|:-------------------|----------------:|------------:|\n| No                 |             0   |       100   |\n| Yes                |            87.5 |        12.5 |\n| All                |            40.8 |        59.2 |\n\n\n\n\nVentilated patients showed a 70% mortality rate vs 35% mortality rate for the non-ventilated patients.\n\n\nClinical Variable Intercorrelations:\n\n\n\n\n\n\n\n\nFigure 6: Correlation Heatmap\n\n\n\n\n\nThe expanded heatmap, Figure 6, highlights strongest relationships: neutrophils - lymphocytes. Notable absent: age-outcome correlation due to categorical target encoding. Weak age associations with blood metrics suggest independent demographic effects.\n\n\n\nStatistical Hypothesis Testing:\n\n\nGender-Survival Chi-square: χ²=2.68, p=0.1016\n\n\nAge by Outcome T-test: t=-6.90, p=0.0000\n\n\n\nChi-square test for gender-survival association:\nA Chi-square test of independence was performed to examine the relationship between patient gender and survival outcome.\nThe analysis produced \\(x^2\\) statistic of 2.68 with a corresponding p-value of 0.1016. Since the p-value is greater than the standard significance level of 0.05, we fail to reject the null hyporhesis, that gender and survival are independent.\nThe statistical evidence suggests there is no significant association between a patient’s gender and their likelyhood of recovery within this specific data-set. This supports the visual observation from Figure 2 , indicating similar proportional outcomes for both males and females.\n\n\nT-Test for age difference by outcome:\nAn independent samples T-test was conducted to compare the mean age of patients who recovered versus those who did not recover.\nThe T-test yielded a T-statistic of -6.90 and an extremely low p-value. As the p-value is well below the 0.05 significance threshold, we reject the null hypothesis.\nThe negative T-statistic indicates that patients who recovered were, on average, younger than those who did not recover. This provides support for Figure 3 , highlighting age as a critical predictor of outcome in this cohort."
  },
  {
    "objectID": "projects/covid/covid19_eda.html#key-takeaways",
    "href": "projects/covid/covid19_eda.html#key-takeaways",
    "title": "Covid 19 Dataset",
    "section": "Key Takeaways:",
    "text": "Key Takeaways:\n\n\n1. Age &gt;60 years: 76% mortality risk (t=-6.90, p&lt;0.0001, d=1.4)\n\n\n2. No missing data - excellent quality\n\n\n3. Multimodal age distribution (peaks: 30-40, 50-60, 60-70)\n\n\n4. Gender not significant predictor\n\n\n5. Ventilation: 70% case fatality rate vs 35% non-ventilated\n\n\n\n=== LIMITATIONS ===\n\n\n1. Small sample (n=103)\n\n\n2. Single hospital, early pandemic (Apr-Aug 2020)\n\n\n3. No treatment effect analysis\n\n\n4. Limited geographic representation\n\n\n\nLicense and Data Usage Terms:\nThe data used in this analysis is provided under the Creative Commons Attribution 4.0 International License (CC BY 4.0)."
  },
  {
    "objectID": "projects/viralMetagenomics/viralMetagenomics.html",
    "href": "projects/viralMetagenomics/viralMetagenomics.html",
    "title": "Pathogen Identification from Clinical Metagenomics Data",
    "section": "",
    "text": "The objective of this project was to develop and execute a bioinformatics workflow to identify potential pathogens from clinical metagenomics data. The workflow encompassed several key steps, including quality control of raw sequencing reads, host depletion to remove human DNA, de novo assembly of unmapped reads, and classification using BLAST. The ultimate goal was to determine the presence of clinically relevant pathogens in the sample. By performing host depletation and classification, I was able to demonstrate the ability to isolate the microbial signal from a Bronchoalveolar lavage (BAL) sample."
  },
  {
    "objectID": "projects/viralMetagenomics/viralMetagenomics.html#aim",
    "href": "projects/viralMetagenomics/viralMetagenomics.html#aim",
    "title": "Pathogen Identification from Clinical Metagenomics Data",
    "section": "",
    "text": "The objective of this project was to develop and execute a bioinformatics workflow to identify potential pathogens from clinical metagenomics data. The workflow encompassed several key steps, including quality control of raw sequencing reads, host depletion to remove human DNA, de novo assembly of unmapped reads, and classification using BLAST. The ultimate goal was to determine the presence of clinically relevant pathogens in the sample. By performing host depletation and classification, I was able to demonstrate the ability to isolate the microbial signal from a Bronchoalveolar lavage (BAL) sample."
  },
  {
    "objectID": "projects/viralMetagenomics/viralMetagenomics.html#data-acquisition",
    "href": "projects/viralMetagenomics/viralMetagenomics.html#data-acquisition",
    "title": "Pathogen Identification from Clinical Metagenomics Data",
    "section": "Data Acquisition:",
    "text": "Data Acquisition:\nThe raw sequencing data for this project was accessed from the NCBI SRA (BioProject: PRJNA1327646), originating from a published study on COPD microbiomes (Chen et al., 2025). The authors of the study specified that the data deposited in the SRA had already undergone in silico human host DNA removal prior to submission.\nTo ensure data integrity and quantify any residual human reads, a Quality Control (QC) step was performed. Raw reads were aligned against the human reference genome (hg38) using BWA (Li and Durbin, 2009)."
  },
  {
    "objectID": "projects/viralMetagenomics/viralMetagenomics.html#quality-control-of-samples",
    "href": "projects/viralMetagenomics/viralMetagenomics.html#quality-control-of-samples",
    "title": "Pathogen Identification from Clinical Metagenomics Data",
    "section": "Quality Control of Samples:",
    "text": "Quality Control of Samples:\n\nFastq Statistics:\nThe seqkit stats (Shen, Sipos and Zhao, 2024) output describes the raw sequencing data before alignment. The command is used to generate a tabular statistical summary of FASTA/Q files. By default, it automatically detects the sequence type of the files.\n\nShow code\nenvDir=\"/home/devonallies/micromamba/envs/bioinfo/bin\"\ndataDir=\"../../../../data\"\n\n${envDir}/seqkit stats ${dataDir}/reads/SRR35359600_*.fastq\n\n\n\n\nTable 1: Statistics of fastq files\n\n\n\nprocessed files:  0 / 2 [------] ETA: 0s\n\u001b[1A\u001b[Jprocessed files:  0 / 2 [------] ETA: 0s\n\u001b[1A\u001b[Jprocessed files:  2 / 2 [======] ETA: 0s\n\u001b[1A\u001b[Jprocessed files:  2 / 2 [] ETA: 0s. done\nfile                                        format  type   num_seqs      sum_len  min_len  avg_len  max_len\n../../../../data/reads/SRR35359600_1.fastq  FASTQ   DNA   1,246,647  182,039,361       15      146      150\n../../../../data/reads/SRR35359600_2.fastq  FASTQ   DNA   1,246,647  181,919,031       15    145.9      150"
  },
  {
    "objectID": "projects/viralMetagenomics/viralMetagenomics.html#bam-flagstat-statistics",
    "href": "projects/viralMetagenomics/viralMetagenomics.html#bam-flagstat-statistics",
    "title": "Pathogen Identification from Clinical Metagenomics Data",
    "section": "BAM Flagstat Statistics:",
    "text": "BAM Flagstat Statistics:\nThe BAM flagstat statistic summarizes the results after the raw reads have been aligned / mapped to a reference genome.\n\nShow code\nenvDir=\"/home/devonallies/micromamba/envs/bioinfo/bin\"\ndataDir=\"../../../../data\"\nsample=$(basename \"${dataDir}/sort/SRR35359600.sorted.bam\" .sorted.bam)\n\necho \"------------------------------\"\necho \"Processing sample: $sample\"\necho \"-------------------------------\"\n${envDir}/samtools flagstat ${dataDir}/sort/SRR35359600.sorted.bam\n\n\n\n\nTable 2: Statistics of BAM files\n\n\n\n------------------------------\nProcessing sample: SRR35359600\n-------------------------------\n2627660 + 0 in total (QC-passed reads + QC-failed reads)\n2493294 + 0 primary\n0 + 0 secondary\n134366 + 0 supplementary\n0 + 0 duplicates\n0 + 0 primary duplicates\n1637803 + 0 mapped (62.33% : N/A)\n1503437 + 0 primary mapped (60.30% : N/A)\n2493294 + 0 paired in sequencing\n1246647 + 0 read1\n1246647 + 0 read2\n1169744 + 0 properly paired (46.92% : N/A)\n1496222 + 0 with itself and mate mapped\n7215 + 0 singletons (0.29% : N/A)\n241104 + 0 with mate mapped to a different chr\n113350 + 0 with mate mapped to a different chr (mapQ&gt;=5)\n\n\n\n\n\ntotal: The total number of reads processed, separated into those passing Quality Control (QC) and those failing.\nmapped: The percentage of reads that successfully aligned to the reference genome. This is critical for assessing the efficiency of the alignment process and the relevance of the reference genome.\npaired in sequencing: Confirms all reads were generated from paired-end sequencing, which is important for downstream analyses that rely on paired-end data.\nproperly paired: Reads that aligned to the reference genome in the expected orientation and distance. A high percentage indicates good library preparation and alignment quality.\nsingletons: Reads that did not have a properly paired mate."
  },
  {
    "objectID": "projects/viralMetagenomics/viralMetagenomics.html#host-depletion",
    "href": "projects/viralMetagenomics/viralMetagenomics.html#host-depletion",
    "title": "Pathogen Identification from Clinical Metagenomics Data",
    "section": "Host Depletion:",
    "text": "Host Depletion:\nHost depletion is a critical step in viral metagenomics to enrich for viral sequences by removing host-derived reads. This process can be achieved through various methods, including computational approaches that filter out host sequences based on alignment to a reference genome or using specialized tools designed for host depletion.\n\nShow code\n# Set the paths for files and environment\nenvDir=\"/home/devonallies/micromamba/envs/bioinfo/bin\"\ndataDir=\"../../../../data\"\n\nsample=$(basename \"${dataDir}/sort/SRR35359600.sorted.bam\" .sorted.bam)\n\necho \"------------------------------\"\necho \"Processing sample: $sample\"\necho \"-------------------------------\"\n\n${envDir}/samtools collate -u -O ${dataDir}/sort/SRR35359600.sorted.bam | \\\n${envDir}/samtools fastq -f4 -1 \"${dataDir}/unmapped/${sample}_R1.fq\" -2 \"${dataDir}/unmapped/${sample}_R2.fq\" -s \"${dataDir}/unmapped/${sample}_singleton.fq\"\n\n\n\n\nTable 3: Removing unmapped reads\n\n\n\n------------------------------\nProcessing sample: SRR35359600\n-------------------------------\n[M::bam2fq_mainloop] discarded 7215 singletons\n[M::bam2fq_mainloop] processed 989857 reads\n\n\n\n\nHost depletion is a critical step in clinical metagenomics because clinical samples (like blood, tissue, or respirator fluid) are typically dominated by human DNA, which can constitute 90% - 99% of the sequencing data. By removing the host background, sensitivity is increased, it enables accurate De Novo Assembly, and improves downstream analysis. The singletons are placed in a singleton.fq file.\nWhile a notable percentage indicated in Table 2, 62.33%, of the reads still aligned to the human genome, the remaining non-host reads are sufficient for downstream classification."
  },
  {
    "objectID": "projects/viralMetagenomics/viralMetagenomics.html#de-nova-assembly",
    "href": "projects/viralMetagenomics/viralMetagenomics.html#de-nova-assembly",
    "title": "Pathogen Identification from Clinical Metagenomics Data",
    "section": "De Nova Assembly:",
    "text": "De Nova Assembly:\nMegahit (Li et al., 2016) is a fast and memory-efficient de novo assembler for large and complex metagenomics data sets. It uses succinct de Bruijn graphs to represent the input data, which significantly reduces memory usage compared to traditional de Bruijn graph representations. Megahit is designed to handle large-scale metagenomic datasets, making it suitable for assembling genomes from environmental samples with high diversity and complexity.\n\nShow code\n# Set the paths for files and environment\nenvDir=\"/home/devonallies/micromamba/envs/bioinfo/bin\"\ndataDir=\"../../../../data\"\n\nsample=$(basename \"${dataDir}/unmapped/SRR35359600\" _R1.fq)\nr1=${dataDir}/unmapped/${sample}_R1.fq\nr2=${dataDir}/unmapped/${sample}_R2.fq\nsingleton=${dataDir}/unmapped/${sample}_singleton.fq\n\necho \"------------------------------\"\necho \"Processing sample: $sample\"\necho \"-------------------------------\"\n\n${envDir}/megahit -1 $r1 -2 $r2 -r $singleton -o \"${dataDir}/megahit/${sample}\" --out-prefix $sample -f\n\n\n\n\nTable 4: De Nova Assembly uisng Megahits\n\n\n\n------------------------------\nProcessing sample: SRR35359600\n-------------------------------\n2026-02-05 14:24:59 - MEGAHIT v1.2.9\n2026-02-05 14:24:59 - Using megahit_core with POPCNT and BMI2 support\n2026-02-05 14:24:59 - Convert reads to binary library\n2026-02-05 14:25:00 - b'INFO  sequence/io/sequence_lib.cpp  :   75 - Lib 0 (/mnt/069ABB979ABB822B/learning/data/unmapped/SRR35359600_R1.fq,/mnt/069ABB979ABB822B/learning/data/unmapped/SRR35359600_R2.fq): pe, 982642 reads, 150 max length'\n2026-02-05 14:25:00 - b'INFO  sequence/io/sequence_lib.cpp  :   75 - Lib 1 (/mnt/069ABB979ABB822B/learning/data/unmapped/SRR35359600_singleton.fq): se, 7215 reads, 150 max length'\n2026-02-05 14:25:00 - b'INFO  utils/utils.h                 :  152 - Real: 1.0382\\tuser: 0.6381\\tsys: 0.1387\\tmaxrss: 85204'\n2026-02-05 14:25:00 - k-max reset to: 141 \n2026-02-05 14:25:00 - Start assembly. Number of CPU threads 8 \n2026-02-05 14:25:00 - k list: 21,29,39,59,79,99,119,141 \n2026-02-05 14:25:00 - Memory used: 45253907251\n2026-02-05 14:25:00 - Extract solid (k+1)-mers for k = 21 \n2026-02-05 14:25:09 - Build graph for k = 21 \n2026-02-05 14:25:13 - Assemble contigs from SdBG for k = 21\n2026-02-05 14:25:22 - Local assembly for k = 21\n2026-02-05 14:25:28 - Extract iterative edges from k = 21 to 29 \n2026-02-05 14:25:29 - Build graph for k = 29 \n2026-02-05 14:25:31 - Assemble contigs from SdBG for k = 29\n2026-02-05 14:25:40 - Local assembly for k = 29\n2026-02-05 14:25:46 - Extract iterative edges from k = 29 to 39 \n2026-02-05 14:25:47 - Build graph for k = 39 \n2026-02-05 14:25:49 - Assemble contigs from SdBG for k = 39\n2026-02-05 14:25:59 - Local assembly for k = 39\n2026-02-05 14:26:08 - Extract iterative edges from k = 39 to 59 \n2026-02-05 14:26:08 - Build graph for k = 59 \n2026-02-05 14:26:10 - Assemble contigs from SdBG for k = 59\n2026-02-05 14:26:17 - Local assembly for k = 59\n2026-02-05 14:26:24 - Extract iterative edges from k = 59 to 79 \n2026-02-05 14:26:25 - Build graph for k = 79 \n2026-02-05 14:26:26 - Assemble contigs from SdBG for k = 79\n2026-02-05 14:26:30 - Local assembly for k = 79\n2026-02-05 14:26:38 - Extract iterative edges from k = 79 to 99 \n2026-02-05 14:26:39 - Build graph for k = 99 \n2026-02-05 14:26:40 - Assemble contigs from SdBG for k = 99\n2026-02-05 14:26:44 - Local assembly for k = 99\n2026-02-05 14:26:51 - Extract iterative edges from k = 99 to 119 \n2026-02-05 14:26:52 - Build graph for k = 119 \n2026-02-05 14:26:53 - Assemble contigs from SdBG for k = 119\n2026-02-05 14:26:56 - Local assembly for k = 119\n2026-02-05 14:27:04 - Extract iterative edges from k = 119 to 141 \n2026-02-05 14:27:05 - Build graph for k = 141 \n2026-02-05 14:27:05 - Assemble contigs from SdBG for k = 141\n2026-02-05 14:27:08 - Merging to output final contigs \n2026-02-05 14:27:09 - 9116 contigs, total 7205375 bp, min 210 bp, max 16159 bp, avg 790 bp, N50 908 bp\n2026-02-05 14:27:09 - ALL DONE. Time elapsed: 129.526783 seconds \n\n\n\n\n\nShow code\n# Set the paths for files and environment\nenvDir=\"/home/devonallies/micromamba/envs/bioinfo/bin\"\ndataDir=\"../../../../data\"\nsample=$(basename \"${dataDir}/unmapped/SRR35359600\" _R1.fq)\n\n${envDir}/seqkit stats ${dataDir}/megahit/${sample}/${sample}.contigs.fa\n\n\n\n\nTable 5: Statistics of Megahit Assembly\n\n\n\nfile                                                         format  type  num_seqs    sum_len  min_len  avg_len  max_len\n../../../../data/megahit/SRR35359600/SRR35359600.contigs.fa  FASTA   DNA      9,116  7,205,375      210    790.4   16,159"
  },
  {
    "objectID": "projects/viralMetagenomics/viralMetagenomics.html#basic-local-alignment-search-tool",
    "href": "projects/viralMetagenomics/viralMetagenomics.html#basic-local-alignment-search-tool",
    "title": "Pathogen Identification from Clinical Metagenomics Data",
    "section": "Basic Local Alignment Search Tool:",
    "text": "Basic Local Alignment Search Tool:\nBlast is the gold standard for comparing a query sequence (DNA, RNA, or Protein) against a massive database of known sequences to find regions of similarity\n\n\nShow code\n#|label: tbl-blast\n#|tbl-cap: \"Output of blast result\"\n\nenvDir=\"/home/devonallies/micromamba/envs/bioinfo/bin\"\ndataDir=\"../../../../data\"\nsample=$(basename \"${dataDir}/unmapped/SRR35359600\" _R1.fq)\n\n${envDir}/makeblastdb -out ${dataDir}/megahit/${sample}/${sample} -in ${dataDir}/megahit/${sample}/${sample}.contigs.fa -dbtype nucl -parse_seqids\n\n${envDir}/blastdbcmd -db ${dataDir}/megahit/${sample}/${sample} -entry all -outfmt \"%l %a\" &gt; \"${dataDir}/megahit/${sample}/${sample}_blast.txt\"\n\ncat ${dataDir}/megahit/${sample}/${sample}_blast.txt | sort -rn | head\n\n\n\n\nBuilding a new DB, current time: 02/06/2026 09:52:51\nNew DB name:   /mnt/069ABB979ABB822B/learning/data/megahit/SRR35359600/SRR35359600\nNew DB title:  ../../../../data/megahit/SRR35359600/SRR35359600.contigs.fa\nSequence type: Nucleotide\nDeleted existing Nucleotide BLAST database named /mnt/069ABB979ABB822B/learning/data/megahit/SRR35359600/SRR35359600\nKeep MBits: T\nMaximum file size: 3000000000B\nAdding sequences from FASTA; added 9116 sequences in 0.204801 seconds.\n\n\n16159 k141_9107\n15399 k141_6789\n15193 k141_7744\n9747 k141_191\n8971 k141_6695\n8401 k141_4630\n8326 k141_89\n8324 k141_2178\n7369 k141_8263\n6914 k141_3816"
  },
  {
    "objectID": "projects/viralMetagenomics/viralMetagenomics.html#sample-identification",
    "href": "projects/viralMetagenomics/viralMetagenomics.html#sample-identification",
    "title": "Pathogen Identification from Clinical Metagenomics Data",
    "section": "Sample Identification:",
    "text": "Sample Identification:\n\nShow code\nenvDir=\"/home/devonallies/micromamba/envs/bioinfo/bin\"\ndataDir=\"../../../../data\"\nsample=$(basename \"${dataDir}/unmapped/SRR35359600\" _R1.fq)\n\n${envDir}/blastdbcmd -db ${dataDir}/megahit/${sample}/${sample} -entry k141_9107 &gt; \"${dataDir}/megahit/${sample}/k141_9107.fa\"\n${envDir}/blastdbcmd -db ${dataDir}/megahit/${sample}/${sample} -entry k141_6789 &gt; \"${dataDir}/megahit/${sample}/k141_6789.fa\"\n${envDir}/blastdbcmd -db ${dataDir}/megahit/${sample}/${sample} -entry k141_7744 &gt; \"${dataDir}/megahit/${sample}/k141_7744.fa\"\n\n# Blast k141_9107\necho \"------------------------------\"\necho \"Processing contig: k141_9107\"\necho \"-------------------------------\"\n${envDir}/blastn -db ${dataDir}/databases/ref_prok_rep_genomes -query ${dataDir}/megahit/${sample}/k141_9107.fa -outfmt \"6 qseqid pident evalue length stitle\" | awk '$2 &gt;= 99.0 && $4 &gt;= 1000'\n\n# Blast k141_6789\necho \"------------------------------\"\necho \"Processing contig: k141_6789\"\necho \"-------------------------------\"\n${envDir}/blastn -db ${dataDir}/databases/ref_prok_rep_genomes -query ${dataDir}/megahit/${sample}/k141_6789.fa -outfmt \"6 qseqid pident evalue length stitle\" | awk '$2 &gt;= 99.0 && $4 &gt;= 1000'\n\n# Blast k141_7744\necho \"------------------------------\"\necho \"Processing contig: k141_7744\"\necho \"-------------------------------\"\n${envDir}/blastn -db ${dataDir}/databases/ref_prok_rep_genomes -query ${dataDir}/megahit/${sample}/k141_7744.fa -outfmt \"6 qseqid pident evalue length stitle\" | awk '$2 &gt;= 99.0 && $4 &gt;= 1000'\n\n\n\n\nTable 6: Top BLAST Hits for Sample\n\n\n\n------------------------------\nProcessing contig: k141_9107\n-------------------------------\nk141_9107   99.409  0.0 5757    Acinetobacter parvus strain CCM 7030 tig00001935, whole genome shotgun sequence\nk141_9107   99.274  0.0 1102    Acinetobacter ursingii NIPH 706 acLZz-supercont1.16, whole genome shotgun sequence\nk141_9107   99.186  0.0 1106    Acinetobacter thermotolerans strain ANC 7924 chromosome, complete genome\nk141_9107   99.008  0.0 1109    Acinetobacter baumannii strain ATCC 19606 chromosome, complete genome\nk141_9107   99.005  0.0 1106    Acinetobacter baumannii strain ATCC 19606 chromosome, complete genome\nk141_9107   99.092  0.0 1101    Acinetobacter baumannii strain ATCC 19606 chromosome, complete genome\n------------------------------\nProcessing contig: k141_6789\n-------------------------------\nk141_6789   99.864  0.0 5156    Faucicola atlantae strain NCTC11091, whole genome shotgun sequence\n------------------------------\nProcessing contig: k141_7744\n-------------------------------\n\n\n\n\nThe BLAST results indicate a statistically definitive match between the query sequence and the subject database. The alignment parameters - specifically the 99.409% percent identity, the 5757 basepair alignmnent length, and the E-value of 0.0 - provides evidence of high-confidence sequence homology.\n\nPercent Identity: The high degree of nucleotide conservation suggests that the query and subject sequences are nearly identical. This level of similarity is characteristic of sequences derived from the same species or highly conserved orthologous rehions within closely related strains.\nAlignment Length: The substantial length of the aligned region bolsters the validity of the match.\nExpect Value: An E-value of 0.0 represents a probability that is indistinguishable from zero. It signifies that the likelyhood of observing such a high-scoring alignment by random chance within the search space is non-existent.\n\nThe verified non-host reads were assembled into contigs using megahit (Li et al., 2016) and subsequently classified via BLAST (Camacho et al., 2009). The analysis yielded a high-confidence identification based on the alignment of contig k141_9107\n\nShow code\nenvDir=\"/home/devonallies/micromamba/envs/bioinfo/bin\"\ndataDir=\"../../../../data\"\nsample=$(basename \"${dataDir}/unmapped/SRR35359600\" _R1.fq)\n\n${envDir}/amrfinder -n ${dataDir}/megahit/${sample}/${sample}.contigs.fa --database ${dataDir}/databases/armfinder/amr_db/2026-01-21.1/ --plus\n\n\n\n\nTable 7: AMRFinder Results for Sample\n\n\n\nRunning: /home/devonallies/micromamba/envs/bioinfo/bin/amrfinder -n ../../../../data/megahit/SRR35359600/SRR35359600.contigs.fa --database ../../../../data/databases/armfinder/amr_db/2026-01-21.1/ --plus\nSoftware directory: /home/devonallies/micromamba/envs/bioinfo/bin/\nSoftware version: 4.2.5\nDatabase directory: /mnt/069ABB979ABB822B/learning/data/databases/armfinder/amr_db/2026-01-21.1\nDatabase version: 2026-01-21.1\nAMRFinder translated nucleotide search\n  - include -O ORGANISM, --organism ORGANISM option to add mutation searches and suppress common proteins\nRunning blastx\nMaking report\nProtein id  Contig id   Start   Stop    Strand  Element symbol  Element name    Scope   Type    Subtype Class   Subclass    Method  Target length   Reference sequence length   % Coverage of reference % Identity to reference Alignment length    Closest reference accession Closest reference name  HMM accession   HMM description\nNA  k141_2664   760 1617    +   blaTEM-116  broad-spectrum class A beta-lactamase TEM-116   core    AMR AMR BETA-LACTAM BETA-LACTAM ALLELEX 286 286 100.00  100.00  286 WP_000027050.1  broad-spectrum class A beta-lactamase TEM-116   NA  NA\namrfinder took 47 seconds to complete\n\n\n\n\nAMRFINDER identified the gene blaTEM-116, which is a broad-spectrum class A beta-lactamase. This enzyme breaks down beta-lactam antibiotics."
  },
  {
    "objectID": "projects/viralMetagenomics/viralMetagenomics.html#conclusion",
    "href": "projects/viralMetagenomics/viralMetagenomics.html#conclusion",
    "title": "Pathogen Identification from Clinical Metagenomics Data",
    "section": "Conclusion:",
    "text": "Conclusion:\nThe identification of Acinetobacter parvus, is a gram-negative aerobic bacterium notable for forming small colonies in cultures, with the metrics displayed in Table 6, indicates a strong result."
  }
]